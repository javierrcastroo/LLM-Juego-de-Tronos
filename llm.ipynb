{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Juego de Tronos (Libro 1): QA + Imagen (Notebook independiente)\n",
    "\n",
    "Este notebook es **autocontenido**: no depende de archivos `.py` externos.\n",
    "Modelos:\n",
    "- QA/Planner: `Qwen/Qwen3-30B-A3B-Thinking-2507-FP8`\n",
    "- Imagen: `stabilityai/stable-diffusion-3.5-large`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install -U pandas pyarrow beautifulsoup4 lxml faiss-cpu sentence-transformers transformers accelerate diffusers safetensors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "EPUB_PATH = '/content/drive/MyDrive/juego_de_tronos.epub'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import zipfile\n",
    "from typing import Optional\n",
    "\n",
    "import faiss\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from bs4 import BeautifulSoup\n",
    "from diffusers import StableDiffusion3Pipeline\n",
    "from sentence_transformers import SentenceTransformer, CrossEncoder\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "QWEN_MODEL_ID = 'Qwen/Qwen3-30B-A3B-Thinking-2507-FP8'\n",
    "EMBED_MODEL_ID = 'BAAI/bge-m3'\n",
    "RERANKER_MODEL_ID = 'BAAI/bge-reranker-large'\n",
    "SD3_MODEL_ID = 'stabilityai/stable-diffusion-3.5-large'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text: str) -> str:\n",
    "    text = re.sub(r\"\\r\\n?\", \"\\n\", text)\n",
    "    text = re.sub(r\"\\n\\s*\\n+\", \"\\n\\n\", text)\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "def extract_title_and_pov(text: str) -> tuple[Optional[str], Optional[str]]:\n",
    "    lines = [ln.strip() for ln in text.split(\"\\n\") if ln.strip()]\n",
    "    for line in lines[:20]:\n",
    "        if re.match(r\"^[A-ZÁÉÍÓÚÑÜ]+.*\\(\\d+\\)$\", line):\n",
    "            return line, line.split(\"(\")[0].strip()\n",
    "    return None, None\n",
    "\n",
    "\n",
    "def list_xhtml_text_files(zf: zipfile.ZipFile) -> list[str]:\n",
    "    candidates = [f for f in zf.namelist() if f.lower().endswith((\".xhtml\", \".html\"))]\n",
    "    preferred = [f for f in candidates if '/text/' in f.lower() or '/texto/' in f.lower()]\n",
    "    return sorted(preferred if preferred else candidates)\n",
    "\n",
    "\n",
    "def extract_chapters(epub_path: str) -> pd.DataFrame:\n",
    "    if not os.path.exists(epub_path):\n",
    "        raise FileNotFoundError(f'No existe EPUB_PATH: {epub_path}')\n",
    "\n",
    "    chapters = []\n",
    "    with zipfile.ZipFile(epub_path, 'r') as zf:\n",
    "        for file_name in list_xhtml_text_files(zf):\n",
    "            soup = BeautifulSoup(zf.read(file_name), 'lxml')\n",
    "            text = clean_text(soup.get_text('\\n'))\n",
    "            if len(text) < 800:\n",
    "                continue\n",
    "            title, pov = extract_title_and_pov(text)\n",
    "            chapters.append({\n",
    "                'chapter_id': len(chapters),\n",
    "                'epub_file': file_name,\n",
    "                'title': title,\n",
    "                'pov': pov,\n",
    "                'text': text,\n",
    "                'n_chars': len(text),\n",
    "            })\n",
    "    return pd.DataFrame(chapters)\n",
    "\n",
    "\n",
    "def chunk_text(text: str, chunk_size: int = 4500, overlap: int = 750):\n",
    "    if chunk_size <= overlap:\n",
    "        raise ValueError('chunk_size debe ser mayor que overlap')\n",
    "    start = 0\n",
    "    chunks = []\n",
    "    while start < len(text):\n",
    "        end = min(start + chunk_size, len(text))\n",
    "        piece = text[start:end].strip()\n",
    "        if piece:\n",
    "            chunks.append((start, end, piece))\n",
    "        start += (chunk_size - overlap)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def build_chunks(chapters_df: pd.DataFrame, chunk_size: int = 4500, overlap: int = 750) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for _, ch in chapters_df.iterrows():\n",
    "        for i, (s, e, t) in enumerate(chunk_text(ch['text'], chunk_size, overlap)):\n",
    "            rows.append({\n",
    "                'chunk_id': f\"{int(ch['chapter_id'])}_{i}\",\n",
    "                'chapter_id': int(ch['chapter_id']),\n",
    "                'epub_file': ch['epub_file'],\n",
    "                'title': ch['title'],\n",
    "                'pov': ch['pov'],\n",
    "                'start_char': s,\n",
    "                'end_char': e,\n",
    "                'text': t,\n",
    "                'n_chars': len(t),\n",
    "            })\n",
    "    return pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chapters_df = extract_chapters(EPUB_PATH)\n",
    "chunks_df = build_chunks(chapters_df)\n",
    "\n",
    "chapters_df.to_parquet('chapters.parquet', index=False)\n",
    "chunks_df.to_parquet('chunks.parquet', index=False)\n",
    "\n",
    "print('Capítulos:', len(chapters_df), '| Chunks:', len(chunks_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder = SentenceTransformer(EMBED_MODEL_ID)\n",
    "reranker = CrossEncoder(RERANKER_MODEL_ID)\n",
    "\n",
    "\n",
    "def embed_texts(texts, batch_size=32):\n",
    "    vecs = embedder.encode(\n",
    "        texts,\n",
    "        batch_size=batch_size,\n",
    "        show_progress_bar=True,\n",
    "        convert_to_numpy=True,\n",
    "        normalize_embeddings=True,\n",
    "    )\n",
    "    return vecs.astype('float32')\n",
    "\n",
    "emb = embed_texts(chunks_df['text'].tolist())\n",
    "index = faiss.IndexFlatIP(emb.shape[1])\n",
    "index.add(emb)\n",
    "print('FAISS listo:', index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(QWEN_MODEL_ID, use_fast=True)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    QWEN_MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto',\n",
    ")\n",
    "\n",
    "\n",
    "def build_context(passages_df: pd.DataFrame, max_chars_each: int = 1800) -> str:\n",
    "    blocks = []\n",
    "    for _, row in passages_df.iterrows():\n",
    "        txt = row['text'][:max_chars_each].strip()\n",
    "        blocks.append(f\"[{row['chunk_id']}] ({row['pov']} | {row['title']})\\n{txt}\")\n",
    "    return '\\n\\n'.join(blocks)\n",
    "\n",
    "\n",
    "def run_chat(messages, max_new_tokens=400):\n",
    "    prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors='pt').to(model.device)\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=False,\n",
    "        temperature=0.0,\n",
    "        top_p=1.0,\n",
    "        repetition_penalty=1.03,\n",
    "    )\n",
    "    new_tokens = out[0][inputs['input_ids'].shape[1]:]\n",
    "    return tokenizer.decode(new_tokens, skip_special_tokens=True).strip()\n",
    "\n",
    "\n",
    "def retrieve_passages(question: str, top_k=12, faiss_k=100) -> pd.DataFrame:\n",
    "    q_emb = embed_texts([question], batch_size=1)\n",
    "    scores, idxs = index.search(q_emb, faiss_k)\n",
    "    cand = chunks_df.iloc[idxs[0].tolist()].copy()\n",
    "    cand['faiss_score'] = scores[0]\n",
    "    cand['rerank_score'] = reranker.predict([(question, t) for t in cand['text'].tolist()])\n",
    "    return cand.sort_values('rerank_score', ascending=False).head(top_k).reset_index(drop=True)\n",
    "\n",
    "\n",
    "def answer_question(question: str, passages_df: pd.DataFrame) -> str:\n",
    "    context = build_context(passages_df)\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': (\n",
    "                \"Eres experto en 'Juego de Tronos' (Libro 1). \"\n",
    "                \"Responde solo con hechos de los fragmentos. \"\n",
    "                \"Si no hay evidencia, di exactamente: 'No encontrado en los fragmentos proporcionados'. \"\n",
    "                \"Añade [chunk_id] al final de cada frase factual.\"\n",
    "            ),\n",
    "        },\n",
    "        {'role': 'user', 'content': f'Pregunta: {question}\\n\\nFragmentos:\\n{context}'},\n",
    "    ]\n",
    "    return run_chat(messages, max_new_tokens=420)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scene_schema = {\n",
    "    'style': 'string',\n",
    "    'subject': 'string',\n",
    "    'setting': 'string',\n",
    "    'time_of_day': 'day|night|dawn|dusk|unknown',\n",
    "    'mood': 'string',\n",
    "    'characters': [{'name': 'string', 'appearance': 'string', 'clothing': 'string'}],\n",
    "    'action': 'string',\n",
    "    'camera': 'string',\n",
    "    'important_objects': ['string'],\n",
    "    'avoid': ['string'],\n",
    "}\n",
    "\n",
    "\n",
    "def extract_first_json(raw: str) -> dict:\n",
    "    start = raw.find('{')\n",
    "    if start < 0:\n",
    "        raise ValueError('No se encontró JSON en salida del planner')\n",
    "\n",
    "    depth = 0\n",
    "    in_str = False\n",
    "    esc = False\n",
    "    for i in range(start, len(raw)):\n",
    "        ch = raw[i]\n",
    "        if in_str:\n",
    "            if esc:\n",
    "                esc = False\n",
    "            elif ch == '\\\\':\n",
    "                esc = True\n",
    "            elif ch == '\"':\n",
    "                in_str = False\n",
    "            continue\n",
    "        else:\n",
    "            if ch == '\"':\n",
    "                in_str = True\n",
    "                continue\n",
    "\n",
    "        if ch == '{':\n",
    "            depth += 1\n",
    "        elif ch == '}':\n",
    "            depth -= 1\n",
    "            if depth == 0:\n",
    "                return json.loads(raw[start:i+1])\n",
    "\n",
    "    raise ValueError('JSON no balanceado en salida del planner')\n",
    "\n",
    "\n",
    "def plan_scene(question: str, answer: str, passages_df: pd.DataFrame) -> dict:\n",
    "    context = build_context(passages_df, max_chars_each=1400)\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': (\n",
    "                'You are an art director for text-to-image generation. '\n",
    "                'Return ONLY a valid JSON object following the provided schema. '\n",
    "                'Use only details grounded in context and answer. '\n",
    "                'No actor names, no TV adaptation references.'\n",
    "            ),\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': (\n",
    "                f'Question: {question}\\n\\nAnswer: {answer}\\n\\nContext:\\n{context}\\n\\n'\n",
    "                f'Schema: {json.dumps(scene_schema, ensure_ascii=False)}'\n",
    "            ),\n",
    "        },\n",
    "    ]\n",
    "    raw = run_chat(messages, max_new_tokens=360)\n",
    "    return extract_first_json(raw)\n",
    "\n",
    "\n",
    "def scene_to_prompt(scene: dict) -> tuple[str, str]:\n",
    "    chars = []\n",
    "    for c in (scene.get('characters') or [])[:3]:\n",
    "        desc = ', '.join([x for x in [c.get('name'), c.get('appearance'), c.get('clothing')] if x])\n",
    "        if desc:\n",
    "            chars.append(desc)\n",
    "\n",
    "    parts = [\n",
    "        'cinematic still, medieval fantasy, high detail, natural lighting',\n",
    "        scene.get('style', ''),\n",
    "        f\"subject: {scene.get('subject', '')}\",\n",
    "        scene.get('action', ''),\n",
    "        f\"setting: {scene.get('setting', '')}\",\n",
    "        f\"time: {scene.get('time_of_day', '')}\",\n",
    "        f\"mood: {scene.get('mood', '')}\",\n",
    "        f\"characters: {'; '.join(chars)}\" if chars else '',\n",
    "        f\"camera: {scene.get('camera', '')}\",\n",
    "        'props: ' + ', '.join(scene.get('important_objects', [])) if scene.get('important_objects') else '',\n",
    "    ]\n",
    "    prompt = ', '.join([p.strip() for p in parts if p and str(p).strip()])\n",
    "\n",
    "    avoid = (scene.get('avoid') or []) + [\n",
    "        'text, watermark, logo',\n",
    "        'tv actors, celebrity face',\n",
    "        'modern clothing',\n",
    "        'low quality, blurry',\n",
    "    ]\n",
    "    negative = ', '.join(dict.fromkeys(avoid))\n",
    "    return prompt, negative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_pipe = StableDiffusion3Pipeline.from_pretrained(\n",
    "    SD3_MODEL_ID,\n",
    "    torch_dtype=torch.bfloat16,\n",
    ").to('cuda')\n",
    "image_pipe.enable_attention_slicing()\n",
    "\n",
    "\n",
    "def ask_and_draw(question: str, top_k=12, faiss_k=100, seed: Optional[int] = None):\n",
    "    passages = retrieve_passages(question, top_k=top_k, faiss_k=faiss_k)\n",
    "    answer = answer_question(question, passages)\n",
    "    scene = plan_scene(question, answer, passages)\n",
    "    prompt, negative = scene_to_prompt(scene)\n",
    "\n",
    "    gen = None\n",
    "    if seed is not None:\n",
    "        gen = torch.Generator(device='cuda').manual_seed(seed)\n",
    "\n",
    "    image = image_pipe(\n",
    "        prompt=prompt,\n",
    "        negative_prompt=negative,\n",
    "        num_inference_steps=30,\n",
    "        guidance_scale=6.0,\n",
    "        width=1024,\n",
    "        height=1024,\n",
    "        generator=gen,\n",
    "    ).images[0]\n",
    "\n",
    "    return {\n",
    "        'answer': answer,\n",
    "        'passages': passages,\n",
    "        'scene': scene,\n",
    "        'prompt': prompt,\n",
    "        'negative_prompt': negative,\n",
    "        'image': image,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = ask_and_draw('¿Cómo escapó Tyrion del Nido de Águilas?', seed=7)\n",
    "print(result['answer'])\n",
    "print('PROMPT:', result['prompt'])\n",
    "result['image']\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}